{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SBERT\n",
    "\n",
    "This notebook shows how the model that is used in the report is trained and created. It consists of multiple steps:\n",
    "1. Downloading the data from the MSMARCO website.\n",
    "2. Preparing the data for loading into the model.\n",
    "3. Creating a datamodule for loading the data into the model.\n",
    "4. Defining the model module, which defines the structure of the model, the loss function, the optimizer, and the metrics used to evaluate the model.\n",
    "5. Finding the optimal threshold for the model.\n",
    "6. Training the model.\n",
    "7. Making the plot of the model size vs the F1 score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4129455045087a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloading the Data\n",
    "\n",
    "This part of the notebook simply downloads the necessary data from the MSMARCO website. The data is then stored in the `data/raw` folder for later processing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eee3591e47ba1047"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/qidpidtriples.train.full.2.tsv.gz data/raw/qidpidtriples.train.full.2.tsv.gz\n",
    "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz data/raw/msmarco-test2019-queries.tsv.gz\n",
    "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/collection.tar.gz data/raw/collection.tar.gz\n",
    "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-passagetest2019-top1000.tsv.gz data/raw/msmarco-passagetest2019-top1000.tsv.gz\n",
    "!wget https://trec.nist.gov/data/deep/2019qrels-pass.txt data/raw/2019qrels-pass.txt\n",
    "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz data/raw/msmarco-test2019-queries.tsv.gz\n",
    "!gzip -d data/raw/qidpidtriples.train.full.2.tsv.gz\n",
    "!gzip -d data/raw/msmarco-test2019-queries.tsv.gz\n",
    "!gzip -d data/raw/msmarco-passagetest2019-top1000.tsv.gz\n",
    "!tar -xvf data/raw/collection.tar.gz -C data/raw/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed192be01b3c15ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the Data for Loading\n",
    "\n",
    "This part of the notebook prepares the data by converting the data from multiple TSV files into the [WebDataset format](https://webdataset.github.io/webdataset/) which can then be loaded efficiently into a DataLoader. This step also processes the triple dataset into a dataset of positive and negative pairs, such that each triple sample is split into a positive and negative pair. Moreover, this step also creates the a validation set from the training set, and creates a test set from the MSMARCO test set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29b400d3717a3471"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import click\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_passages(corpus_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        corpus_path,\n",
    "        sep=\"\\t\",\n",
    "        names=[\"passage_id\", \"passage\"],\n",
    "        dtype={\"passage_id\": int, \"passage\": str},\n",
    "    ).set_index(\"passage_id\")\n",
    "\n",
    "\n",
    "def load_queries(queries_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        queries_path,\n",
    "        sep=\"\\t\",\n",
    "        names=[\"query_id\", \"query\"],\n",
    "        dtype={\"query_id\": int, \"query\": str},\n",
    "    ).set_index(\"query_id\")\n",
    "\n",
    "\n",
    "def load_qrels(qrels_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        qrels_path,\n",
    "        sep=\"\\t\",\n",
    "        names=[\"query_id\", \"positive_passage_id\", \"negative_passage_id\"],\n",
    "        dtype={\n",
    "            \"query_id\": int,\n",
    "            \"positive_passage_id\": int,\n",
    "            \"negative_passage_id\": int,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def load_test_qrels(qrels_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        qrels_path,\n",
    "        sep=\" \",\n",
    "        names=[\"query_id\", \"Q0\", \"passage_id\", \"rating\"],\n",
    "        dtype={\"query_id\": int, \"Q0\": str, \"passage_id\": int, \"rating\": int},\n",
    "    )\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--data_path\", default=\"data/raw/\", type=str)\n",
    "@click.option(\"--output_path\", default=\"data/processed/\", type=str)\n",
    "@click.option(\"--passages_path\", default=\"collection.tsv\", type=str)\n",
    "@click.option(\"--queries_path\", default=\"queries.train.tsv\", type=str)\n",
    "@click.option(\n",
    "    \"--qrels_path\", default=\"qidpidtriples.train.full.2.tsv\", type=str\n",
    ")\n",
    "@click.option(\"--subsample\", default=1_000_000, type=int)\n",
    "@click.option(\"--seed\", default=42, type=int)\n",
    "@click.option(\"--validation_fraction\", default=0.1, type=float)\n",
    "def prepare_data(\n",
    "        data_path: str,\n",
    "        output_path: str,\n",
    "        passages_path: str,\n",
    "        queries_path: str,\n",
    "        qrels_path: str,\n",
    "        subsample: int,\n",
    "        seed: int,\n",
    "        validation_fraction: float,\n",
    ") -> None:\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    print(\"Loading data\")\n",
    "    passages = load_passages(os.path.join(data_path, passages_path))\n",
    "    queries = load_queries(os.path.join(data_path, queries_path))\n",
    "    qrels = load_qrels(os.path.join(data_path, qrels_path))\n",
    "\n",
    "    qrels_values = qrels.sample(n=subsample, random_state=seed).values\n",
    "    train_qrels = qrels_values[\n",
    "                  : int(len(qrels_values) * (1 - validation_fraction))\n",
    "                  ]\n",
    "    validation_qrels = qrels_values[\n",
    "                       int(len(qrels_values) * (1 - validation_fraction)) :\n",
    "                       ]\n",
    "\n",
    "    print(\"Writing to train shards\")\n",
    "    write_shards(\"train\", output_path, passages, queries, train_qrels)\n",
    "\n",
    "    print(\"Writing to validation shards\")\n",
    "    write_shards(\n",
    "        \"validation\", output_path, passages, queries, validation_qrels\n",
    "    )\n",
    "\n",
    "    print(\"Writing to test shards\")\n",
    "    test_queries = load_queries(\n",
    "        os.path.join(data_path, \"msmarco-test2019-queries.tsv\")\n",
    "    )\n",
    "    test_qrels = load_test_qrels(os.path.join(data_path, \"2019qrels-pass.txt\"))\n",
    "\n",
    "    write_test_shards(output_path, passages, test_queries, test_qrels)\n",
    "\n",
    "\n",
    "def write_test_shards(\n",
    "        output_path: str,\n",
    "        passages: pd.DataFrame,\n",
    "        queries: pd.DataFrame,\n",
    "        test_qrels: pd.DataFrame,\n",
    "):\n",
    "    test_sink = wds.TarWriter(os.path.join(output_path, f\"test.tar\"))\n",
    "    for query_id, _, passage_id, rating in tqdm(\n",
    "            test_qrels.values, desc=\"Writing to test shards\"\n",
    "    ):\n",
    "        query = queries.loc[query_id, \"query\"]\n",
    "        passage = passages.loc[passage_id, \"passage\"]\n",
    "\n",
    "        test_sink.write(\n",
    "            {\n",
    "                \"__key__\": f\"{query_id}-{passage_id}\",\n",
    "                \"query.pyd\": query,\n",
    "                \"passage.pyd\": passage,\n",
    "                \"label.cls\": 0 if rating < 2 else 1,\n",
    "                \"rating.cls\": rating,\n",
    "            }\n",
    "        )\n",
    "    test_sink.close()\n",
    "\n",
    "\n",
    "def write_shards(\n",
    "        name: str,\n",
    "        output_path: str,\n",
    "        passages: pd.DataFrame,\n",
    "        queries: pd.DataFrame,\n",
    "        qrels,\n",
    "):\n",
    "    ONE_GIGABYTE = 1024**3\n",
    "    sink = wds.ShardWriter(\n",
    "        os.path.join(output_path, f\"{name}-%d.tar\"),\n",
    "        maxsize=ONE_GIGABYTE,\n",
    "        maxcount=100000,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    for query_id, positive_passage_id, negative_passage_id in tqdm(\n",
    "            qrels, desc=\"Writing to shards\"\n",
    "    ):\n",
    "        query = queries.loc[query_id, \"query\"]\n",
    "        positive_passage = passages.loc[positive_passage_id, \"passage\"]\n",
    "        negative_passage = passages.loc[negative_passage_id, \"passage\"]\n",
    "\n",
    "        sink.write(\n",
    "            {\n",
    "                \"__key__\": f\"{query_id}-{positive_passage_id}\",\n",
    "                \"query.pyd\": query,\n",
    "                \"passage.pyd\": positive_passage,\n",
    "                \"label.cls\": 1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        sink.write(\n",
    "            {\n",
    "                \"__key__\": f\"{query_id}-{negative_passage_id}\",\n",
    "                \"query.pyd\": query,\n",
    "                \"passage.pyd\": negative_passage,\n",
    "                \"label.cls\": 0,\n",
    "            }\n",
    "        )\n",
    "    sink.close()\n",
    "\n",
    "\n",
    "## The main function is called with the default parameters defined in the click configuration above.\n",
    "prepare_data()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2ae14dfe450869e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a DataModule for the Dataset\n",
    "\n",
    "This datamodule simply creates the dataloaders for loading the dataset into the model. The dataloaders are created using the WebDataset library, which allows for efficient loading of the dataset. The dataloaders are created using the `train-{0..17}.tar` files for training, the `validation-{0..1}.tar` files for validation, and the `test.tar` file for testing.\n",
    "\n",
    "By using a datamodule from Lightning, we can easily use the datamodule with the Trainer class from Lightning, which allows for easy training of the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cec52710fd4eeb89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "import webdataset as wds\n",
    "\n",
    "\n",
    "class MSMarcoDataModule(L.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 256, num_workers: int | None = None, dataset_length: int = 50_000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_workers = (\n",
    "            cpu_count() // 2 if num_workers is None else num_workers\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.validation_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "        self.dataset_length = dataset_length\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    @staticmethod\n",
    "    def to_string(string: bytes) -> str:\n",
    "        return string.decode(\"utf-8\")\n",
    "\n",
    "    @staticmethod\n",
    "    def to_float(string: bytes) -> float:\n",
    "        return float(string.decode(\"utf-8\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def rating_to_class(rating: bytes) -> float:\n",
    "        rating = float(rating.decode(\"utf-8\"))\n",
    "\n",
    "        return 1. if rating >= 1 else 0.\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        self.train_dataset = (\n",
    "            wds.WebDataset(\n",
    "                \"data/processed/train-{0..17}.tar\", shardshuffle=True\n",
    "            )\n",
    "            .with_length(self.dataset_length)\n",
    "            .shuffle(1000)\n",
    "            .to_tuple(\"query.pyd\", \"passage.pyd\", \"label.cls\")\n",
    "            .map_tuple(self.to_string, self.to_string, self.to_float)\n",
    "        )\n",
    "        self.validation_dataset = (\n",
    "            wds.WebDataset(\"data/processed/validation-{0..1}.tar\")\n",
    "            .to_tuple(\"query.pyd\", \"passage.pyd\", \"label.cls\")\n",
    "            .map_tuple(self.to_string, self.to_string, self.to_float)\n",
    "        )\n",
    "\n",
    "        self.test_dataset = (\n",
    "            wds.WebDataset(\"data/processed/test.tar\")\n",
    "            .to_tuple(\"query.pyd\", \"passage.pyd\", \"rating.cls\")\n",
    "            .map_tuple(self.to_string, self.to_string, self.rating_to_class)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset.batched(self.batch_size),\n",
    "            pin_memory=True,\n",
    "            batch_size=None,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset.batched(self.batch_size),\n",
    "            batch_size=None,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.validation_dataset.batched(self.batch_size),\n",
    "            batch_size=None,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        return self.val_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786944a680932a3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Model Module\n",
    "\n",
    "This module defines the structure of the model we are training, which loss function is used, and which optimizer is used. Moreover, it defines the metrics we are using to evaluate the model.\n",
    "\n",
    "The module also defines what we do in each type of step of the training process:\n",
    "1. `training_step` defines what we do in each step of the training process. In this case, we simply calculate the loss and log it.\n",
    "2. `validation_step` defines what we do in each step of the validation process. In this case, we simply calculate the loss and some performance metrics and log them.\n",
    "3. `test_step` defines what we do in each step of the testing process. In this case, we simply calculate the loss and some performance metrics and log them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d09d80c6797ce056"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import wandb\n",
    "from torch import nn, Tensor\n",
    "import lightning as L\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "import torchmetrics\n",
    "from sentence_transformers.util import batch_to_device\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \\\n",
    "    average_precision_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "\n",
    "class SBERT(L.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: SentenceTransformer,\n",
    "            criterion: nn.Module,\n",
    "            lr: float = 1e-5,\n",
    "            compile_model: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformer = model.to(self.device)\n",
    "        self.pooling = models.Pooling(model.get_sentence_embedding_dimension())\n",
    "\n",
    "        self.model = torch.compile(nn.Sequential(\n",
    "            self.transformer,\n",
    "            self.pooling\n",
    "        ), mode=\"max-autotune\", disable=not compile_model)\n",
    "\n",
    "        self.cosine = nn.CosineSimilarity()\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.is_cosine_embedding_loss = isinstance(self.criterion, nn.CosineEmbeddingLoss)\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "        self.train_metrics = torchmetrics.MetricCollection(\n",
    "            {\n",
    "                \"train_accuracy_k1\": torchmetrics.Accuracy(task=\"binary\"),\n",
    "                \"train_accuracy_k3\": torchmetrics.Accuracy(\n",
    "                    task=\"binary\", top_k=3\n",
    "                ),\n",
    "                \"train_accuracy_k5\": torchmetrics.Accuracy(\n",
    "                    task=\"binary\", top_k=5\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.validation_metrics = torchmetrics.MetricCollection(\n",
    "            {\n",
    "                \"val_accuracy_k1\": torchmetrics.Accuracy(task=\"binary\"),\n",
    "                \"val_accuracy_k3\": torchmetrics.Accuracy(\n",
    "                    task=\"binary\", top_k=3\n",
    "                ),\n",
    "                \"val_accuracy_k5\": torchmetrics.Accuracy(\n",
    "                    task=\"binary\", top_k=5\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.test_metrics = torchmetrics.MetricCollection(\n",
    "            {\n",
    "                \"test_accuracy_k1\": torchmetrics.Accuracy(task=\"binary\"),\n",
    "                \"test_accuracy_k3\": torchmetrics.Accuracy(\n",
    "                    task=\"binary\", top_k=3\n",
    "                ),\n",
    "                \"test_accuracy_k5\": torchmetrics.Accuracy(\n",
    "                    task=\"binary\", top_k=5\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.y_test = []\n",
    "        self.y_hat_test = []\n",
    "\n",
    "        self.threshold = 0.5\n",
    "        self.mapped_threshold = 0.5\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\", \"criterion\"])\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        tokens = self.transformer.tokenize(x)\n",
    "        tokens = batch_to_device(tokens, self.device)\n",
    "        return self.model(tokens)\n",
    "\n",
    "    def training_step(self, batch) -> Tensor:\n",
    "        x_question, x_answer, y = batch\n",
    "\n",
    "        output_question = self(x_question)\n",
    "        output_answer = self(x_answer)\n",
    "\n",
    "        embeddings_question = output_question[\"sentence_embedding\"]\n",
    "        embeddings_answer = output_answer[\"sentence_embedding\"]\n",
    "\n",
    "        if self.is_cosine_embedding_loss:\n",
    "            loss = self.criterion(\n",
    "                embeddings_question, embeddings_answer, y\n",
    "            )\n",
    "        else:\n",
    "            similarity = self.cosine(embeddings_question, embeddings_answer)\n",
    "            y_hat, y = similarity.to(torch.float32), y.to(torch.float32)\n",
    "            loss = self.criterion(y_hat, y)\n",
    "            self.train_metrics(y_hat.detach().cpu(), y.detach().cpu())\n",
    "\n",
    "            self.log_dict(\n",
    "                self.train_metrics, on_step=True, on_epoch=True, prog_bar=False\n",
    "            )\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x_question, x_answer, y = batch\n",
    "\n",
    "        output_question = self(x_question)\n",
    "        output_answer = self(x_answer)\n",
    "\n",
    "        embeddings_question = output_question[\"sentence_embedding\"]\n",
    "        embeddings_answer = output_answer[\"sentence_embedding\"]\n",
    "\n",
    "        if self.is_cosine_embedding_loss:\n",
    "            loss = self.criterion(\n",
    "                embeddings_question, embeddings_answer, y\n",
    "            )\n",
    "        else:\n",
    "            similarity = self.cosine(embeddings_question, embeddings_answer)\n",
    "            y_hat, y = similarity.to(torch.float32), y.to(torch.float32)\n",
    "\n",
    "            loss = self.criterion(y_hat, y)\n",
    "            self.validation_metrics(y_hat.detach().cpu(), y.detach().cpu())\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x_question, x_answer, y = batch\n",
    "\n",
    "        output_question = self(x_question)\n",
    "        output_answer = self(x_answer)\n",
    "\n",
    "        embeddings_question = output_question[\"sentence_embedding\"]\n",
    "        embeddings_answer = output_answer[\"sentence_embedding\"]\n",
    "\n",
    "        similarity = self.cosine(embeddings_question, embeddings_answer)\n",
    "        y_hat, y = similarity.to(torch.float32), y.to(torch.float32)\n",
    "\n",
    "        if self.is_cosine_embedding_loss:\n",
    "            loss = self.criterion(\n",
    "                embeddings_question, embeddings_answer, y\n",
    "            )\n",
    "        else:\n",
    "            loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.test_metrics(y_hat.detach().cpu(), y.detach().cpu())\n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            \"y_hat\": y_hat.detach().cpu(),\n",
    "            \"y\": y.detach().cpu(),\n",
    "            \"loss\": loss.detach().cpu()\n",
    "        }\n",
    "\n",
    "    def on_test_batch_end(self, outputs, batch, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        self.y_test.append(outputs[\"y\"])\n",
    "        self.y_hat_test.append(outputs[\"y_hat\"])\n",
    "\n",
    "    def map_y_hat(self, y_hat: np.ndarray) -> np.ndarray:\n",
    "        return (y_hat + 1) / 2\n",
    "\n",
    "    def on_test_end(self) -> None:\n",
    "        y = torch.cat(self.y_test, dim=0)\n",
    "        y_hat = torch.cat(self.y_hat_test, dim=0)\n",
    "\n",
    "        y = y.detach().cpu().numpy()\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        y_hat_mapped = self.map_y_hat(y_hat)\n",
    "\n",
    "        y_pred = np.where(y_hat > self.threshold, 1, 0)\n",
    "        y_pred_mapped = np.where(y_hat_mapped > self.mapped_threshold, 1, 0)\n",
    "\n",
    "        self.log_test_metrics(y, y_hat, y_pred, \"raw\")\n",
    "        self.log_test_metrics(y, y_hat_mapped, y_pred_mapped, \"mapped\")\n",
    "\n",
    "    def log_test_metrics(self, y, y_hat, y_pred, prefix):\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        precision = precision_score(y, y_pred)\n",
    "        recall = recall_score(y, y_pred)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "        roc_auc = roc_auc_score(y, y_hat)\n",
    "        average_precision = average_precision_score(y, y_hat)\n",
    "\n",
    "        self.logger.experiment.log(\n",
    "            {\n",
    "                f\"test_{prefix}_confusion_matrix\": wandb.Image(ConfusionMatrixDisplay.from_predictions(y, y_pred).figure_),\n",
    "                f\"test_{prefix}_roc_curve\": wandb.Image(RocCurveDisplay.from_predictions(y, y_hat).figure_),\n",
    "                f\"test_{prefix}_accuracy\": accuracy,\n",
    "                f\"test_{prefix}_precision\": precision,\n",
    "                f\"test_{prefix}_recall\": recall,\n",
    "                f\"test_{prefix}_f1\": f1,\n",
    "                f\"test_{prefix}_roc_auc\": roc_auc,\n",
    "                f\"test_{prefix}_average_precision\": average_precision\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "        x_question, x_answer, y = batch\n",
    "\n",
    "        output_question = self(x_question)\n",
    "        output_answer = self(x_answer)\n",
    "\n",
    "        embeddings_question = output_question[\"sentence_embedding\"]\n",
    "        embeddings_answer = output_answer[\"sentence_embedding\"]\n",
    "\n",
    "        similarity = self.cosine(embeddings_question, embeddings_answer)\n",
    "        y_hat, y = similarity.to(torch.float32), y.to(torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"y_hat\": y_hat.detach().cpu(),\n",
    "            \"y\": y.detach().cpu(),\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36d5cdc6ea6f2af1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding the Optimal Threshold\n",
    "\n",
    "This function is simply used to find the optimal threshold for the model. The optimal threshold is found by finding the threshold that maximizes the F1 score on the validation set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c9b9a7e99295a01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def normalize(x: torch.Tensor) -> torch.Tensor:\n",
    "    return (x + 1) / 2\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_threshold(trainer: L.Trainer, module: L.LightningModule, data_module: L.LightningDataModule, map: bool = False) -> tuple[float, float]:\n",
    "    module.eval()\n",
    "    predictions: list[dict[str, torch.Tensor]] = trainer.predict(module, datamodule=data_module)\n",
    "    module.train()\n",
    "\n",
    "    y = torch.cat([batch[\"y\"] for batch in predictions]).cpu().numpy()\n",
    "    y_hat = torch.cat([batch[\"y_hat\"] for batch in predictions]).cpu().numpy()\n",
    "\n",
    "    if map:\n",
    "        y_hat = normalize(y_hat)\n",
    "\n",
    "    best_threshold = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    for threshold in range(0, 100, 1):\n",
    "        threshold /= 100\n",
    "\n",
    "        y_pred = y_hat > threshold\n",
    "\n",
    "        f1 = f1_score(y, y_pred)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13a03fe3e8a5280"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model\n",
    "\n",
    "Finally, we can train the model and use all that have been defined until this point. We use the `Trainer` class from Lightning to train the model. We use the `find_threshold` function defined above to find the optimal threshold for the model. We then use this threshold to evaluate the model on the test set.\n",
    "\n",
    "5 different models are trained, each with a different model architecture. The models are trained for 10,000 steps with a batch size of 64. The models are trained using mixed precision training, which allows for faster training and lower memory usage. The models have all been trained on the HPC server cluster of DTU using A100 GPUs. Every other parameter is kept at the default value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9be0b4f5c37d4581"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from datamodule import MSMarcoDataModule\n",
    "from find_threshold import find_threshold\n",
    "from sbert_model import SBERT\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import click\n",
    "import os\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--batch_size\", default=256, type=int)\n",
    "@click.option(\"--model\", default=\"bert-base-uncased\", type=str)\n",
    "@click.option(\"--epochs\", default=1, type=int)\n",
    "@click.option(\"--seed\", default=42, type=int)\n",
    "@click.option(\"--num_workers\", default=None, type=int)\n",
    "@click.option(\"--lr\", default=1e-5, type=float)\n",
    "@click.option(\"--precision\", default=None, type=str)\n",
    "@click.option(\"--dev\", default=False, type=bool, is_flag=True)\n",
    "@click.option(\"--num_steps\", default=5000, type=int)\n",
    "@click.option(\"--compile\", default=False, type=bool)\n",
    "@click.option(\"--loss_type\", default=\"MSE\", type=str)\n",
    "@click.option(\"--test\", default=False, type=bool, is_flag=True)\n",
    "@click.option(\"--load_model\", default=None, type=str)\n",
    "@click.option(\"--cpu\", default=False, type=bool, is_flag=True)\n",
    "def train(\n",
    "        batch_size: int,\n",
    "        model: str,\n",
    "        epochs: int,\n",
    "        seed: int,\n",
    "        num_workers: int,\n",
    "        lr: float,\n",
    "        precision: str | None = None,\n",
    "        dev: bool = False,\n",
    "        num_steps: int = -1,\n",
    "        compile: bool = True,\n",
    "        loss_type: str = \"cosine\",\n",
    "        test: bool = False,\n",
    "        load_model: str = None,\n",
    "        cpu: bool = False,\n",
    "):\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    L.seed_everything(seed)\n",
    "\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    model = SentenceTransformer(model)\n",
    "    print(model)\n",
    "\n",
    "    logger = WandbLogger(\n",
    "        project=\"dl_sbert\", entity=\"colodingdongs\", log_model=\"all\"\n",
    "    )\n",
    "\n",
    "    logger.experiment.config.update(\n",
    "        {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"model\": model,\n",
    "            \"epochs\": epochs,\n",
    "            \"seed\": seed,\n",
    "            \"num_workers\": num_workers,\n",
    "            \"lr\": lr,\n",
    "            \"precision\": precision,\n",
    "            \"dev\": dev,\n",
    "            \"max_steps\": num_steps,\n",
    "            \"loss_type\": loss_type,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=epochs,\n",
    "        accelerator=\"auto\" if not cpu else \"cpu\",\n",
    "        devices=1 if torch.cuda.is_available() else \"auto\",\n",
    "        deterministic=True,\n",
    "        logger=logger,\n",
    "        precision=precision,\n",
    "        fast_dev_run=dev,\n",
    "        max_steps=num_steps,\n",
    "    )\n",
    "\n",
    "    datamodule = MSMarcoDataModule(\n",
    "        batch_size=batch_size, num_workers=num_workers, dataset_length=num_steps\n",
    "    )\n",
    "\n",
    "    criterion = torch.nn.CosineEmbeddingLoss() if loss_type == \"cosine\" else torch.nn.MSELoss()\n",
    "\n",
    "    if load_model is None:\n",
    "        l_module = SBERT(model, criterion, lr=lr, compile_model=compile)\n",
    "    else:\n",
    "        artifact = logger.experiment.use_artifact(load_model, type=\"model\")\n",
    "        artifact_dir = artifact.download()\n",
    "\n",
    "        l_module = SBERT.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\", model=model, criterion=criterion, lr=lr)\n",
    "\n",
    "    if test:\n",
    "        trainer.test(l_module, datamodule)\n",
    "        return\n",
    "\n",
    "    trainer.fit(l_module, datamodule)\n",
    "\n",
    "    threshold, best_f1 = find_threshold(trainer, l_module, datamodule)\n",
    "    logger.experiment.config.update({\"threshold\": threshold})\n",
    "    logger.experiment.log({\"best_val_f1\": best_f1})\n",
    "\n",
    "    mapped_threshold, best_mapped_f1 = find_threshold(trainer, l_module, datamodule, map=True)\n",
    "    logger.experiment.config.update({\"mapped_threshold\": mapped_threshold})\n",
    "    logger.experiment.log({\"best_mapped_val_f1\": best_f1})\n",
    "\n",
    "    l_module.threshold = threshold\n",
    "    l_module.mapped_threshold = mapped_threshold\n",
    "\n",
    "    trainer.test(l_module, datamodule)\n",
    "\n",
    "model_names = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"bert-large-uncased\",\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"microsoft/MiniLM-L12-H384-uncased\",\n",
    "    \"nreimers/MiniLM-L6-H384-uncased\"\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    train(\n",
    "        batch_size=64,\n",
    "        model=model_name,\n",
    "        num_steps=10_000,\n",
    "        precision=\"16-mixed\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75aa1340c55a9978"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making the Plot\n",
    "\n",
    "This part of the notebook simply makes the plot of the model size vs the F1 score. The data is loaded from the `models/model_outputs` folder, which contains the output of the models trained above. The outputs are manually downloaded from the Weights & Biases website, and then stored in the `models/model_outputs` folder, but these are simply the config of each model and the metrics logged during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "468d979fcebba37d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "\n",
    "def load_data(directory: str):\n",
    "    \"\"\"\n",
    "    Loads the data from the given directory.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    params = {\n",
    "        \"BERT-base\": 110,\n",
    "        \"BERT-large\": 336,\n",
    "        \"DistilBERT\": 67,\n",
    "        \"MiniLM-L6\": 22.7,\n",
    "        \"MiniLM-L12\": 33.4,\n",
    "    }\n",
    "    for filename, params in params.items():\n",
    "        with open(os.path.join(directory, f\"{filename}.json\")) as f:\n",
    "            model_output = json.load(f)\n",
    "            model_output[\"model_name\"] = filename\n",
    "            model_output[\"params\"] = params\n",
    "        with open(os.path.join(directory, f\"{filename}.config.yaml\")) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            model_output[\"lr\"] = config[\"lr\"][\"value\"]\n",
    "            model_output[\"batch_size\"] = config[\"batch_size\"][\"value\"]\n",
    "            model_output[\"num_steps\"] = config[\"max_steps\"][\"value\"]\n",
    "            model_output[\"threshold\"] = config[\"threshold\"][\"value\"]\n",
    "            model_output[\"mapped_threshold\"] = config[\"mapped_threshold\"][\"value\"]\n",
    "\n",
    "        data.append(model_output)\n",
    "\n",
    "    return pd.DataFrame.from_records(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data\n",
    "    data = load_data(\"models/model_outputs\")\n",
    "\n",
    "    # Plot the data\n",
    "    with plt.style.context(\"seaborn-v0_8\"):\n",
    "        fig, ax = plt.subplots(layout=\"constrained\", figsize=(42 // 2, 28 // 2))\n",
    "        font = {'size': 32}\n",
    "\n",
    "        plt.rc('font', **font)\n",
    "        #fig.tight_layout()\n",
    "\n",
    "        min_f1, max_f1 = data[\"test_mapped_f1\"].min(), data[\"test_mapped_f1\"].max()\n",
    "        min_params, max_params = data[\"params\"].min(), data[\"params\"].max()\n",
    "\n",
    "        X = data[\"params\"].values.reshape(-1, 1)\n",
    "        y = data[\"test_mapped_f1\"].values.reshape(-1, 1)\n",
    "\n",
    "        #plt.xlim((min_params - 20, max_params + 100))\n",
    "        #plt.ylim(min_f1 - 0.05, max_f1 + 0.05)\n",
    "\n",
    "        fig.suptitle(\"Model Size VS F1-Score\", fontsize=56)\n",
    "\n",
    "        # Change ticks\n",
    "        plt.yticks(np.arange(0.54, 0.6 + 0.005, 0.005), fontsize=32)\n",
    "        xticks = np.arange(25, np.ceil(max_params) + 25, 25)\n",
    "        plt.ylabel(\"F1-Score\", fontsize=32)\n",
    "\n",
    "        plt.xticks(xticks, rotation=-45, fontsize=32)\n",
    "        ax.set_xticklabels([f\"{v}M\" for v in xticks])\n",
    "        plt.xlabel(\"No. params\", fontsize=32)\n",
    "\n",
    "        ax.scatter(data[\"params\"], data[\"test_mapped_f1\"], label=\"F1\", s=200, c=\"red\")\n",
    "\n",
    "        text_positions = {\n",
    "            \"BERT-base\": {\"ha\": \"left\"},\n",
    "            \"BERT-large\": {\"ha\": \"right\"},\n",
    "            \"DistilBERT\": {\"ha\": \"left\"},\n",
    "            \"MiniLM-L6\": {\"ha\": \"left\"},\n",
    "            \"MiniLM-L12\": {\"ha\": \"left\"},\n",
    "        }\n",
    "\n",
    "        # Add Model name to each dot\n",
    "        for i in range(len(data)):\n",
    "            row = data.iloc[i]\n",
    "            ax.annotate(f\"{row['model_name']} ({row['params']}M)\", (row[\"params\"], row[\"test_mapped_f1\"]), fontsize=45, **text_positions[row[\"model_name\"]])\n",
    "\n",
    "    fig.savefig(\"model-vs-f1.png\", dpi=600)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4e61c900305faea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
